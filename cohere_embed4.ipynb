{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import cohere\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "ASTRA_DB_APPLICATION_TOKEN = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
    "ASTRA_DB_APPLICATION_ENDPOINT = os.getenv(\"ASTRA_DB_APPLICATION_ENDPOINT\")\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "co = cohere.ClientV2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 26 pages to base64\n",
      "First image base64 length: 792382\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from pdf2image import convert_from_bytes\n",
    "\n",
    "pdf_url = \"https://arxiv.org/pdf/2407.01449\"\n",
    "response = requests.get(pdf_url)\n",
    "pdf_data = response.content\n",
    "\n",
    "images = convert_from_bytes(pdf_data)\n",
    "\n",
    "base64_images = []\n",
    "\n",
    "for img in images:\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format='PNG')\n",
    "    img_data = buffer.getvalue()\n",
    "    \n",
    "    base64_str = base64.b64encode(img_data).decode('utf-8')\n",
    "\n",
    "    image_base64 = f\"data:image/png;base64,{base64_str}\"\n",
    "    base64_images.append(image_base64)\n",
    "\n",
    "print(f\"Converted {len(base64_images)} pages to base64\")\n",
    "print(f\"First image base64 length: {len(base64_images[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = co.embed(\n",
    "    model=\"embed-v4.0\",\n",
    "    input_type=\"image\",\n",
    "    embedding_types=[\"float\"],\n",
    "    images=base64_images,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collection(name=\"cohere_embed_4\", keyspace=\"default_keyspace\", database.api_endpoint=\"https://d085f1e6-07c1-4039-9c2d-e9a7902fccc1-us-east-2.apps.astra.datastax.com\", api_options=FullAPIOptions(token=StaticTokenProvider(AstraCS:axmt...), ...))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from astrapy import DataAPIClient\n",
    "from astrapy.constants import VectorMetric\n",
    "from astrapy.info import CollectionDefinition\n",
    "\n",
    "db = DataAPIClient(\n",
    "    token=ASTRA_DB_APPLICATION_TOKEN,\n",
    ").get_database_by_api_endpoint(api_endpoint=ASTRA_DB_APPLICATION_ENDPOINT)\n",
    "\n",
    "collection_definition = (\n",
    "    CollectionDefinition.builder()\n",
    "    .set_vector_dimension(1536)\n",
    "    .set_vector_metric(VectorMetric.DOT_PRODUCT)\n",
    "    .set_indexing(\"deny\", [\"annotations\", \"logs\"])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "db.create_collection(\n",
    "    name=\"cohere_embed_4\",\n",
    "    definition=collection_definition,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db.get_collection(\n",
    "    name=\"cohere_embed_4\",\n",
    ")\n",
    "\n",
    "for i, embedding in enumerate(response.embeddings.float_):\n",
    "    collection.insert_one(\n",
    "        {\n",
    "            \"page_number\": i,\n",
    "            \"url\": pdf_url,\n",
    "            \"$vector\": embedding,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = co.embed(\n",
    "    texts=[\"What is ColPali?\"],\n",
    "    model=\"embed-v4.0\",\n",
    "    input_type=\"search_query\",\n",
    "    embedding_types=[\"float\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = collection.find(\n",
    "    {},\n",
    "    limit=5,\n",
    "    include_similarity=True,\n",
    "    sort={\"$vector\": query_vector.embeddings.float_[0]},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ColPali is a concept and model architecture based on Vision Language Models (VLMs) designed to simplify document retrieval. It efficiently indexes documents using visual features, aiming to improve query matching with late interaction mechanisms. ColPali offers quick and easy-to-train indexing that outperforms other retrieval systems on benchmarks like ViDoRe. It focuses on combining visual and textual understanding to provide better retrieval performance, fast queries, and high throughput corpus indexation.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "pages = [base64_images[page[\"page_number\"]] for page in cursor]\n",
    "\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "\n",
    "\n",
    "def summarize_pdf_pages(base64_images, query: str):\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Answer the user's question based on only the context provided.\"\n",
    "        }, \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": query}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    for _, img_b64 in enumerate(base64_images):\n",
    "        messages[1][\"content\"].append({\n",
    "            \"type\": \"image_url\",\n",
    "            \"image_url\": {\n",
    "                \"url\": img_b64\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=4000\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "\n",
    "summarize_pdf_pages(pages, \"What is ColPali?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
